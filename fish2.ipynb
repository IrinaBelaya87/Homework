{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Nature Conservancy Fisheries Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "784aaee522ae53eff2274a388350b1b1dd60649b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "263db29157d5633d6f9e7340ab5efec72c677b66"
   },
   "source": [
    "# Загружаем разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "76496f443d36d16b961aeef10b365e3822b06a2b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "# TODO: скачайте данные и сохраните в директорию:\n",
    "TRAIN_PREFIX = './Рыбки/train'\n",
    "\n",
    "def load_boxes():\n",
    "    boxes = dict()\n",
    "    for path in glob('boxes/*.json'):\n",
    "        label = os.path.basename(path).split('_', 1)[0]\n",
    "        with open(path) as src:\n",
    "            boxes[label] = json.load(src)\n",
    "            for annotation in boxes[label]:\n",
    "                basename = os.path.basename(annotation['filename'])\n",
    "                annotation['filename'] = os.path.join(TRAIN_PREFIX, label.upper(), basename)\n",
    "            for annotation in boxes[label]:\n",
    "                for rect in annotation['annotations']:\n",
    "                    rect['x'] += rect['width'] / 2\n",
    "                    rect['y'] += rect['height'] / 2\n",
    "    return boxes\n",
    "\n",
    "def draw_boxes(annotation, rectangles=None, image_size=None):\n",
    "    \n",
    "    def _draw(img, rectangles, scale_x, scale_y, color=(0, 255, 0)):\n",
    "        for rect in rectangles:\n",
    "            pt1 = (int((rect['x'] - rect['width'] / 2) * scale_x),\n",
    "                   int((rect['y'] - rect['height'] / 2) * scale_y))\n",
    "            pt2 = (int((rect['x'] + rect['width'] / 2) * scale_x),\n",
    "                   int((rect['y'] + rect['height'] / 2) * scale_y))\n",
    "            img = cv2.rectangle(img.copy(), pt1, pt2, \n",
    "                                color=color, thickness=4)\n",
    "        return img\n",
    "    \n",
    "    scale_x, scale_y = 1., 1.\n",
    "    \n",
    "    img = cv2.imread(annotation['filename'], cv2.IMREAD_COLOR)[...,::-1]\n",
    "    if image_size is not None:\n",
    "        scale_x = 1. * image_size[0] / img.shape[1]\n",
    "        scale_y = 1. * image_size[1] / img.shape[0]\n",
    "        img = cv2.resize(img, image_size)\n",
    "        \n",
    "    img = _draw(img, annotation['annotations'], scale_x, scale_y)\n",
    "    \n",
    "    if rectangles is not None:\n",
    "        img = _draw(img, rectangles, 1., 1., (255, 0, 0))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализируем разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = load_boxes()  # разметка детекций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alb</td>\n",
       "      <td>1719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bet</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dol</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lag</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shark</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yft</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  count\n",
       "0    alb   1719\n",
       "1    bet    200\n",
       "2    dol    117\n",
       "3    lag     67\n",
       "4  shark    176\n",
       "5    yft    734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(k, len(v)) for k, v in boxes.items()],\n",
    "             columns=['class', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "bb49d388931db2cbd5d8f08b9104299ca90a8c5a"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-562ed529897e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}x{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-33adfb74482a>\u001b[0m in \u001b[0;36mdraw_boxes\u001b[1;34m(annotation, rectangles, image_size)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mscale_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mscale_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6), dpi=120)\n",
    "img = draw_boxes(boxes['lag'][17])\n",
    "plt.imshow(img)\n",
    "plt.title('{}x{}'.format(*img.shape));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0caa7502a0deb8e5e18773b6d2be8ed2f8d0dd4f"
   },
   "source": [
    "### Распределение размеров разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "8db3e3e9aa63c1216d3a1f13526d74ab3abe31a8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations = sum([box['annotations']\n",
    "                  for box in sum(boxes.values(), [])], [])\n",
    "\n",
    "widths = [rect['width'] for rect in annotations]\n",
    "heights = [rect['height'] for rect in annotations]\n",
    "\n",
    "plt.hist(widths)\n",
    "plt.hist(heights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b01ffd790e6e7a81bfee104faa4bfa84ad7597c8"
   },
   "source": [
    "# Экстрактор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f3e6d68bd5e0c8a97319185f25a3b25673482606"
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 750\n",
    "IMG_WIDTH = 1200\n",
    "\n",
    "features = keras.applications.vgg16.VGG16(include_top=False,\n",
    "                                          weights='imagenet',\n",
    "                                          input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "feature_tensor = features.layers[-1].output\n",
    "\n",
    "# дообучаем последние 5 слоев\n",
    "for layer in features.layers[:-5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac4e46072546760703354bd43fa09c5d6bd69fb9"
   },
   "source": [
    "# Сетка якорей (anchor grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SHAPE = (feature_tensor.shape[1].value,\n",
    "                 feature_tensor.shape[2].value)\n",
    "\n",
    "GRID_STEP_H = IMG_HEIGHT / FEATURE_SHAPE[0]\n",
    "GRID_STEP_W = IMG_WIDTH / FEATURE_SHAPE[1]\n",
    "\n",
    "ANCHOR_WIDTH = 150.\n",
    "ANCHOR_HEIGHT = 150. \n",
    "\n",
    "ANCHOR_CENTERS = np.mgrid[GRID_STEP_H/2:IMG_HEIGHT:GRID_STEP_H,\n",
    "                          GRID_STEP_W/2:IMG_WIDTH:GRID_STEP_W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_DICT = {}\n",
    "REVERSE_DICT = {}\n",
    "\n",
    "for i,x in enumerate(boxes.keys()):\n",
    "    LABELS_DICT[x] = i\n",
    "    REVERSE_DICT[i] = x\n",
    "\n",
    "CLASSES_NUM = len(LABELS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alb': 0, 'bet': 1, 'dol': 2, 'lag': 3, 'shark': 4, 'yft': 5},\n",
       " 6,\n",
       " dict_keys(['alb', 'bet', 'dol', 'lag', 'shark', 'yft']),\n",
       " {0: 'alb', 1: 'bet', 2: 'dol', 3: 'lag', 4: 'shark', 5: 'yft'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS_DICT ,CLASSES_NUM, boxes.keys(), REVERSE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in boxes.keys():\n",
    "    for b in boxes[x]:\n",
    "        b['label'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "categorical_labels = to_categorical(list(REVERSE_DICT.keys()), num_classes=CLASSES_NUM)\n",
    "categorical_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'alb', 1: 'bet', 2: 'dol', 3: 'lag', 4: 'shark', 5: 'yft'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REVERSE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(rect, x_scale, y_scale, anchor_x, anchor_y,\n",
    "        anchor_w=ANCHOR_WIDTH, anchor_h=ANCHOR_HEIGHT):\n",
    "    \n",
    "    rect_x1 = (rect['x'] - rect['width'] / 2) * x_scale\n",
    "    rect_x2 = (rect['x'] + rect['width'] / 2) * x_scale\n",
    "    \n",
    "    rect_y1 = (rect['y'] - rect['height'] / 2) * y_scale\n",
    "    rect_y2 = (rect['y'] + rect['height'] / 2) * y_scale\n",
    "    \n",
    "    anch_x1, anch_x2 = anchor_x - anchor_w / 2, anchor_x + anchor_w / 2\n",
    "    anch_y1, anch_y2 = anchor_y - anchor_h / 2, anchor_y + anchor_h / 2\n",
    "    \n",
    "    dx = (min(rect_x2, anch_x2) - max(rect_x1, anch_x1))\n",
    "    dy = (min(rect_y2, anch_y2) - max(rect_y1, anch_y1))\n",
    "    \n",
    "    intersection = dx * dy if (dx > 0 and dy > 0) else 0.\n",
    "    \n",
    "    anch_square = (anch_x2 - anch_x1) * (anch_y2 - anch_y1)\n",
    "    rect_square = (rect_x2 - rect_x1) * (rect_y2 - rect_y1)\n",
    "    union = anch_square + rect_square - intersection\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "def encode_anchors(annotation, img_shape, label_name, iou_thr=0.5):\n",
    "    encoded = np.zeros(shape=(FEATURE_SHAPE[0],\n",
    "                              FEATURE_SHAPE[1], 5+CLASSES_NUM), dtype=np.float32)\n",
    "    x_scale = 1. * IMG_WIDTH / img_shape[1]\n",
    "    y_scale = 1. * IMG_HEIGHT / img_shape[0]\n",
    "    for rect in annotation['annotations']:\n",
    "        scores = []\n",
    "        for row in range(FEATURE_SHAPE[0]):\n",
    "            for col in range(FEATURE_SHAPE[1]):\n",
    "                anchor_x = ANCHOR_CENTERS[1, row, col]\n",
    "                anchor_y = ANCHOR_CENTERS[0, row, col]\n",
    "                score = iou(rect, x_scale, y_scale, anchor_x, anchor_y)\n",
    "                scores.append((score, anchor_x, anchor_y, row, col))\n",
    "        \n",
    "        scores = sorted(scores, reverse=True)\n",
    "        if scores[0][0] < iou_thr:\n",
    "            scores = [scores[0]]  # default anchor\n",
    "        else:\n",
    "            scores = [e for e in scores if e[0] > iou_thr]\n",
    "#TODO add classes one hot\n",
    "        class_num = LABELS_DICT[label_name]\n",
    "    \n",
    "        for score, anchor_x, anchor_y, row, col in scores:\n",
    "            dx = (anchor_x - rect['x'] * x_scale) / ANCHOR_WIDTH\n",
    "            dy = (anchor_y - rect['y'] * y_scale) / ANCHOR_HEIGHT\n",
    "            dw = (ANCHOR_WIDTH - rect['width'] * x_scale) / ANCHOR_WIDTH\n",
    "            dh = (ANCHOR_HEIGHT - rect['height'] * y_scale) / ANCHOR_HEIGHT\n",
    "    \n",
    "            encoded[row, col] = [1., dx, dy, dw, dh]+list(categorical_labels[class_num])\n",
    "        \n",
    "    return encoded\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_prediction(prediction, conf_thr=0.1):\n",
    "    rectangles = []\n",
    "    for row in range(FEATURE_SHAPE[0]):\n",
    "        for col in range(FEATURE_SHAPE[1]):\n",
    "#             print(prediction[row, col])\n",
    "#             print(prediction[row, col])\n",
    "            out_list = prediction[row, col].tolist()\n",
    "            logit, dx, dy, dw, dh, one_hot_class =out_list[0], out_list[1], out_list[2], out_list[3],out_list[4], out_list[5:]\n",
    "            label_index = np.argmax(one_hot_class, axis=0) \n",
    "            conf = _sigmoid(logit)\n",
    "#             print(logit, dx, dy, dw, dh, one_hot_class )\n",
    "            if conf > conf_thr:\n",
    "                anchor_x = ANCHOR_CENTERS[1, row, col]\n",
    "                anchor_y = ANCHOR_CENTERS[0, row, col]\n",
    "                rectangles.append({'x': anchor_x - dx * ANCHOR_WIDTH,\n",
    "                                   'y': anchor_y - dy * ANCHOR_HEIGHT,\n",
    "                                   'width': ANCHOR_WIDTH - dw * ANCHOR_WIDTH,\n",
    "                                   'height': ANCHOR_HEIGHT - dh * ANCHOR_HEIGHT,\n",
    "                                   'conf': conf,\n",
    "                                   'label': REVERSE_DICT[label_index]})\n",
    "    return rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация енкодинга/декодинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a6b4485dff28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-33adfb74482a>\u001b[0m in \u001b[0;36mdraw_boxes\u001b[1;34m(annotation, rectangles, image_size)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mscale_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mscale_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = boxes['alb'][178]\n",
    "# print(boxes['alb'][178]['label'])\n",
    "encoded = encode_anchors(example, (IMG_HEIGHT, IMG_WIDTH), boxes['alb'][178]['label'])\n",
    "# print(encoded[0])\n",
    "\n",
    "decoded = decode_prediction(encoded, conf_thr=0.5)\n",
    "decoded = sorted(decoded, key = lambda e: -e['conf'])\n",
    "# print(decoded)\n",
    "plt.figure(figsize=(6, 6), dpi=120)\n",
    "plt.title('{}'.format(decoded[0]['label']));\n",
    "plt.imshow(draw_boxes(example, decoded[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69b77cba0531fd1ed1c2634e929bee24ac068f7a"
   },
   "source": [
    "## Функция потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "\n",
    "\n",
    "# def weighted_categorical_crossentropy(y_true, y_pred, weights):\n",
    "#     nb_cl = len(weights)\n",
    "#     final_mask = K.zeros_like(y_pred[:, 0])\n",
    "#     y_pred_max = K.max(y_pred, axis=1)\n",
    "#     y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n",
    "#     y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n",
    "#     for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n",
    "#         final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n",
    "#     cross_ent = K.categorical_crossentropy(y_pred, y_true, from_logits=False)\n",
    "#     return cross_ent * final_mask\n",
    "def classification_loss(y_true, y_pred):\n",
    "    class_loss =  K.categorical_crossentropy(y_true[..., 5:], \n",
    "                                      y_pred[..., 5:],\n",
    "                                      from_logits=False)\n",
    "    return class_loss\n",
    "\n",
    "\n",
    "def confidence_loss(y_true, y_pred):\n",
    "    conf_loss = K.binary_crossentropy(y_true[..., 0], \n",
    "                                      y_pred[..., 0],\n",
    "                                      from_logits=True)\n",
    "    return conf_loss\n",
    "\n",
    "def smooth_l1(y_true, y_pred):\n",
    "    abs_loss = K.abs(y_true[..., 1:] - y_pred[..., 1:])\n",
    "    square_loss = 0.5 * K.square(y_true[..., 1:] - y_pred[..., 1:])\n",
    "    mask = K.cast(K.greater(abs_loss, 1.), 'float32')\n",
    "    total_loss = (abs_loss - 0.5) * mask + 0.5 * square_loss * (1. - mask)\n",
    "    return K.sum(total_loss, axis=-1)\n",
    "\n",
    "def total_loss(y_true, y_pred, neg_pos_ratio=3):\n",
    "    batch_size = K.shape(y_true)[0]\n",
    "    \n",
    "    # TODO: добавьте функцию потерь для классификации детекции\n",
    "    \n",
    "    y_true = K.reshape(y_true, (batch_size, -1, 5+CLASSES_NUM))\n",
    "    y_pred = K.reshape(y_pred, (batch_size, -1, 5+CLASSES_NUM))\n",
    "    class_true = K.reshape(y_true[...,5:],(-1,))\n",
    "    class_pred =  K.reshape(y_pred[...,5:],(-1,))\n",
    "#     print(class_true, class_pred)\n",
    "    y_true = y_true[...,:5]\n",
    "    y_pred = y_pred[...,:5]\n",
    "\n",
    "    #classification loss\n",
    "    class_loss = K.categorical_crossentropy(class_true, class_pred, from_logits=False)\n",
    "    \n",
    "    # confidence loss\n",
    "    conf_loss = confidence_loss(y_true, y_pred)\n",
    "    \n",
    "    # smooth l1 loss\n",
    "    loc_loss = smooth_l1(y_true, y_pred)\n",
    "    \n",
    "    # positive examples loss\n",
    "    pos_conf_loss = K.sum(conf_loss * y_true[..., 0], axis=-1)\n",
    "    pos_loc_loss = K.sum(loc_loss * y_true[..., 0], axis=-1)\n",
    "    \n",
    "    # negative examples loss\n",
    "    anchors = K.shape(y_true)[1]\n",
    "    num_pos = K.sum(y_true[..., 0], axis=-1)\n",
    "    num_pos_avg = K.mean(num_pos)\n",
    "    num_neg = K.min([neg_pos_ratio * (num_pos_avg) + 1., K.cast(anchors, 'float32')])\n",
    "    \n",
    "    # hard negative mining\n",
    "    neg_conf_loss, _ = tf.nn.top_k(conf_loss * (1. - y_true[..., 0]),\n",
    "                                   k=K.cast(num_neg, 'int32'))\n",
    "\n",
    "    neg_conf_loss = K.sum(neg_conf_loss, axis=-1)\n",
    "    \n",
    "    # total conf loss\n",
    "    total_conf_loss = (neg_conf_loss + pos_conf_loss) / (num_neg + num_pos + 1e-32)\n",
    "    loc_loss = pos_loc_loss / (num_pos + 1e-32)\n",
    "    \n",
    "    return total_conf_loss + 0.5 * loc_loss + class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, target_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)[...,::-1]\n",
    "    img_shape = img.shape\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    return img_shape, keras.applications.vgg16.preprocess_input(img_resized.astype(np.float32))\n",
    "\n",
    "def data_generator(boxes, batch_size=32):\n",
    "    boxes = sum(boxes.values(), [])\n",
    "    while True:\n",
    "        random.shuffle(boxes)\n",
    "        for i in range(len(boxes)//batch_size):\n",
    "            X, y = [], []\n",
    "            for j in range(i*batch_size,(i+1)*batch_size):\n",
    "                img_shape, img = load_img(boxes[j]['filename'])\n",
    "                # TODO: добавьте one-hot encoding в разметку для классов\n",
    "                y.append(encode_anchors(boxes[j], img_shape, boxes[j]['label']))\n",
    "                X.append(img)\n",
    "            yield np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавляем выход детектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "a8904e155a9d956eecccd59a9b104bcfd20c44e1"
   },
   "outputs": [],
   "source": [
    "output = keras.layers.BatchNormalization()(feature_tensor)\n",
    "\n",
    "# TODO: добавьте выходы для классификации детекции\n",
    "output = keras.layers.Conv2D(5+CLASSES_NUM,\n",
    "                             kernel_size=(1, 1), \n",
    "                             activation='linear',\n",
    "                             kernel_regularizer='l2')(output)\n",
    "\n",
    "model = keras.models.Model(inputs=features.inputs, outputs=output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=1e-3, decay=1e-6)\n",
    "model.compile(optimizer=adam, \n",
    "              loss=total_loss,\n",
    "              metrics={'conf_loss': confidence_loss, 'class_loss': classification_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "88d52a3e5e2f887dcf4cb295c62c3820c97f0db9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8ba22e9946c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                     callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[1;32mD:\\l\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mD:\\l\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    145\u001b[0m       \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\l\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m       \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\l\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\l\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m               \u001b[1;31m# => Serialize calls to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m               \u001b[1;31m# infinite iterator/generator's next() function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m               \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-3f1bcd9372ec>\u001b[0m in \u001b[0;36mdata_generator\u001b[1;34m(boxes, batch_size)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mimg_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[1;31m# TODO: добавьте one-hot encoding в разметку для классов\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-3f1bcd9372ec>\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, target_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMG_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_HEIGHT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mimg_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimg_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "steps_per_epoch = sum(map(len, boxes.values()), 0) / batch_size\n",
    "\n",
    "gen = data_generator(boxes, batch_size=batch_size)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'weights.{epoch:02d}-{loss:.3f}.hdf5',\n",
    "    monitor='loss',\n",
    "    verbose=1,  \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto', period=1)\n",
    "\n",
    "model.fit_generator(generator=gen, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=10000,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результат работы детектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d6d87b271aad9b6f5135870c464f613fce3a31c"
   },
   "outputs": [],
   "source": [
    "example = boxes['lag'][17]\n",
    "\n",
    "_, sample_img = load_img(example['filename'])\n",
    "pred = model.predict(np.array([sample_img,]))[0]\n",
    "\n",
    "decoded = decode_prediction(pred, conf_thr=0.)\n",
    "decoded = sorted(decoded, key=lambda e: -e['conf'])\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=120)\n",
    "img = draw_boxes(example, decoded[:3], (IMG_WIDTH, IMG_HEIGHT))\n",
    "plt.imshow(img)\n",
    "plt.title('{}x{}'.format(*img.shape));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Агрегация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: предскажите класс рыбы для фотографии из тестовой выборки\n",
    "#\n",
    "# Подготовьте файл с предсказаниями вероятностей для каждой фотографии:\n",
    "# image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\n",
    "# img_00001.jpg,1,0,0,0,0,...,0\n",
    "# img_00002.jpg,0.3,0.1,0.6,0,...,0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
